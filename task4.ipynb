{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56361c13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:01.259461Z",
     "iopub.status.busy": "2025-03-19T06:30:01.259268Z",
     "iopub.status.idle": "2025-03-19T06:30:02.825087Z",
     "shell.execute_reply": "2025-03-19T06:30:02.824382Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import gensim.downloader as api\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89268164",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:02.827194Z",
     "iopub.status.busy": "2025-03-19T06:30:02.826948Z",
     "iopub.status.idle": "2025-03-19T06:30:02.830397Z",
     "shell.execute_reply": "2025-03-19T06:30:02.829720Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.0+cu124\n"
     ]
    }
   ],
   "source": [
    "print(f\"PyTorch Version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd38e65a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:02.832468Z",
     "iopub.status.busy": "2025-03-19T06:30:02.832257Z",
     "iopub.status.idle": "2025-03-19T06:30:02.834939Z",
     "shell.execute_reply": "2025-03-19T06:30:02.834385Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "97756959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:02.836701Z",
     "iopub.status.busy": "2025-03-19T06:30:02.836209Z",
     "iopub.status.idle": "2025-03-19T06:30:02.838933Z",
     "shell.execute_reply": "2025-03-19T06:30:02.838391Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44c4ab3f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:02.840460Z",
     "iopub.status.busy": "2025-03-19T06:30:02.840154Z",
     "iopub.status.idle": "2025-03-19T06:30:02.844302Z",
     "shell.execute_reply": "2025-03-19T06:30:02.843498Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6768bc17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:02.846332Z",
     "iopub.status.busy": "2025-03-19T06:30:02.845961Z",
     "iopub.status.idle": "2025-03-19T06:30:02.857231Z",
     "shell.execute_reply": "2025-03-19T06:30:02.856628Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class SentenceClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, architecture=\"rnn\", num_layers=1, bidirectional=False, sentence_embedding_method=\"last\", dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.architecture = architecture.lower()\n",
    "        self.sentence_embedding_method = sentence_embedding_method\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.bidirectional = bidirectional\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        if self.architecture == \"rnn\":\n",
    "            self.rnn = nn.RNN(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=bidirectional, dropout=dropout if num_layers > 1 else 0)\n",
    "        elif self.architecture == \"gru\":\n",
    "            self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=bidirectional, dropout=dropout if num_layers > 1 else 0)\n",
    "        elif self.architecture == \"lstm\":\n",
    "            self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=bidirectional, dropout=dropout if num_layers > 1 else 0)\n",
    "        elif self.architecture == \"cnn\":\n",
    "            self.conv1 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=2, padding=1)\n",
    "            self.conv2 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "            self.conv3 = nn.Conv1d(embedding_dim, hidden_dim, kernel_size=4, padding=2)\n",
    "            self.pool = nn.AdaptiveMaxPool1d(1)\n",
    "\n",
    "        final_hidden_dim = hidden_dim * 2 if bidirectional and architecture != \"cnn\" else hidden_dim\n",
    "        if self.architecture == \"cnn\":\n",
    "            final_hidden_dim = hidden_dim * 3  \n",
    "\n",
    "        self.fc = nn.Linear(final_hidden_dim, output_dim)\n",
    "\n",
    "        if self.sentence_embedding_method == \"attention\" and self.architecture != \"cnn\":\n",
    "            self.attention = nn.Linear(final_hidden_dim, 1)\n",
    "            \n",
    "        if self.architecture in [\"rnn\", \"gru\", \"lstm\"]:\n",
    "            self.flatten_parameters = lambda: None\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        vocab_size = self.embedding.num_embeddings\n",
    "        if text.max().item() >= vocab_size:\n",
    "            raise ValueError(f\"Text contains indices out of vocab range: max index {text.max().item()} >= vocab size {vocab_size}\")\n",
    "\n",
    "        if (text_lengths <= 0).any():\n",
    "            raise ValueError(f\"text_lengths contains non-positive values: {text_lengths}\")\n",
    "        if (text_lengths > text.shape[1]).any():\n",
    "            raise ValueError(f\"text_lengths contains values larger than sequence length: {text_lengths}, max seq length: {text.shape[1]}\")\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        if self.architecture != \"cnn\":\n",
    "            text_lengths_cpu = text_lengths.cpu().to(torch.int64)\n",
    "            packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths_cpu, batch_first=True, enforce_sorted=False)\n",
    "            if self.architecture == \"lstm\":\n",
    "                packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "            else:\n",
    "                packed_output, hidden = self.rnn(packed_embedded)\n",
    "            output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "\n",
    "            if self.sentence_embedding_method == \"last\":\n",
    "                if self.bidirectional:\n",
    "                    hidden = torch.cat((hidden[-2], hidden[-1]), dim=1)\n",
    "                else:\n",
    "                    hidden = hidden[-1]\n",
    "                sentence_embedding = hidden\n",
    "            elif self.sentence_embedding_method == \"mean\":\n",
    "                sentence_embedding = torch.mean(output, dim=1)\n",
    "            elif self.sentence_embedding_method == \"max\":\n",
    "                sentence_embedding = torch.max(output, dim=1)[0]\n",
    "            elif self.sentence_embedding_method == \"attention\":\n",
    "                attn_weights = torch.softmax(self.attention(output), dim=1)\n",
    "                sentence_embedding = torch.sum(output * attn_weights, dim=1)\n",
    "            else:\n",
    "                raise ValueError(\"Unknown sentence embedding method!\")\n",
    "        else:\n",
    "            embedded = embedded.transpose(1, 2)  # [batch_size, embedding_dim, seq_len]\n",
    "            conv1_out = torch.relu(self.conv1(embedded))\n",
    "            conv2_out = torch.relu(self.conv2(embedded))\n",
    "            conv3_out = torch.relu(self.conv3(embedded))\n",
    "            pool1 = self.pool(conv1_out).squeeze(-1)\n",
    "            pool2 = self.pool(conv2_out).squeeze(-1)\n",
    "            pool3 = self.pool(conv3_out).squeeze(-1)\n",
    "            sentence_embedding = torch.cat((pool1, pool2, pool3), dim=1)\n",
    "\n",
    "        sentence_embedding = self.dropout(sentence_embedding)\n",
    "        return self.fc(sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c5eb18c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:02.859492Z",
     "iopub.status.busy": "2025-03-19T06:30:02.859117Z",
     "iopub.status.idle": "2025-03-19T06:30:02.861932Z",
     "shell.execute_reply": "2025-03-19T06:30:02.861536Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b64985",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:02.863928Z",
     "iopub.status.busy": "2025-03-19T06:30:02.863328Z",
     "iopub.status.idle": "2025-03-19T06:30:02.866538Z",
     "shell.execute_reply": "2025-03-19T06:30:02.865973Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83480df4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:02.868408Z",
     "iopub.status.busy": "2025-03-19T06:30:02.868169Z",
     "iopub.status.idle": "2025-03-19T06:30:02.872036Z",
     "shell.execute_reply": "2025-03-19T06:30:02.871571Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text, text_lengths = batch.text\n",
    "\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "\n",
    "        _, predicted = torch.max(predictions, 1)\n",
    "        correct = (predicted == batch.label).float()\n",
    "        acc = correct.sum() / len(batch.label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e15ae519",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:02.873808Z",
     "iopub.status.busy": "2025-03-19T06:30:02.873465Z",
     "iopub.status.idle": "2025-03-19T06:30:02.877221Z",
     "shell.execute_reply": "2025-03-19T06:30:02.876696Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "\n",
    "            _, predicted = torch.max(predictions, 1)\n",
    "            correct = (predicted == batch.label).float()\n",
    "            acc = correct.sum() / len(batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "811eadaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:02.879163Z",
     "iopub.status.busy": "2025-03-19T06:30:02.878840Z",
     "iopub.status.idle": "2025-03-19T06:30:03.784538Z",
     "shell.execute_reply": "2025-03-19T06:30:03.783950Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize='spacy',\n",
    "                  tokenizer_language='en_core_web_sm',\n",
    "                  include_lengths=True,\n",
    "                  pad_first=False,\n",
    "                  batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b71789d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:03.787669Z",
     "iopub.status.busy": "2025-03-19T06:30:03.786876Z",
     "iopub.status.idle": "2025-03-19T06:30:03.790176Z",
     "shell.execute_reply": "2025-03-19T06:30:03.789550Z"
    }
   },
   "outputs": [],
   "source": [
    "LABEL = data.LabelField(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6d0d4bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:03.792457Z",
     "iopub.status.busy": "2025-03-19T06:30:03.792164Z",
     "iopub.status.idle": "2025-03-19T06:30:04.199182Z",
     "shell.execute_reply": "2025-03-19T06:30:04.198476Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = datasets.TREC.splits(TEXT, LABEL, fine_grained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "915e8141",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:04.201836Z",
     "iopub.status.busy": "2025-03-19T06:30:04.201551Z",
     "iopub.status.idle": "2025-03-19T06:30:04.205069Z",
     "shell.execute_reply": "2025-03-19T06:30:04.204487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 5452\n",
      "Number of testing examples: 500\n",
      "{'text': ['How', 'did', 'serfdom', 'develop', 'in', 'and', 'then', 'leave', 'Russia', '?'], 'label': 'DESC'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d3b8ee01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:04.206955Z",
     "iopub.status.busy": "2025-03-19T06:30:04.206575Z",
     "iopub.status.idle": "2025-03-19T06:30:04.212166Z",
     "shell.execute_reply": "2025-03-19T06:30:04.211399Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split(split_ratio=0.8, random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80bfb47f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:04.214349Z",
     "iopub.status.busy": "2025-03-19T06:30:04.213779Z",
     "iopub.status.idle": "2025-03-19T06:30:04.217018Z",
     "shell.execute_reply": "2025-03-19T06:30:04.216498Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 4362\n",
      "Number of validation examples: 1090\n",
      "Number of testing examples: 500\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "027d27fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:04.218878Z",
     "iopub.status.busy": "2025-03-19T06:30:04.218525Z",
     "iopub.status.idle": "2025-03-19T06:30:04.360552Z",
     "shell.execute_reply": "2025-03-19T06:30:04.359713Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, max_size=10000)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bf481ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:04.362706Z",
     "iopub.status.busy": "2025-03-19T06:30:04.362417Z",
     "iopub.status.idle": "2025-03-19T06:30:04.366108Z",
     "shell.execute_reply": "2025-03-19T06:30:04.365504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 8106\n",
      "Unique tokens in LABEL vocabulary: 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87ca36b4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:04.367642Z",
     "iopub.status.busy": "2025-03-19T06:30:04.367423Z",
     "iopub.status.idle": "2025-03-19T06:30:42.338702Z",
     "shell.execute_reply": "2025-03-19T06:30:42.338041Z"
    }
   },
   "outputs": [],
   "source": [
    "word2vec_vectors = api.load('word2vec-google-news-300')\n",
    "embedding_dim = 300\n",
    "vocab_size = len(TEXT.vocab)\n",
    "embedding_matrix = np.random.uniform(-0.25, 0.25, (vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e2f50a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:42.341177Z",
     "iopub.status.busy": "2025-03-19T06:30:42.340820Z",
     "iopub.status.idle": "2025-03-19T06:30:42.365266Z",
     "shell.execute_reply": "2025-03-19T06:30:42.364445Z"
    }
   },
   "outputs": [],
   "source": [
    "for word, idx in TEXT.vocab.stoi.items():\n",
    "    if word in word2vec_vectors:\n",
    "        embedding_matrix[idx] = word2vec_vectors[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d347ed8b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:42.367723Z",
     "iopub.status.busy": "2025-03-19T06:30:42.367192Z",
     "iopub.status.idle": "2025-03-19T06:30:42.373770Z",
     "shell.execute_reply": "2025-03-19T06:30:42.373164Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix = torch.FloatTensor(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d07878d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:42.375843Z",
     "iopub.status.busy": "2025-03-19T06:30:42.375606Z",
     "iopub.status.idle": "2025-03-19T06:30:42.383543Z",
     "shell.execute_reply": "2025-03-19T06:30:42.383022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "GPU Name: NVIDIA RTX 6000 Ada Generation\n",
      "CUDA Version: 12.4\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "if device.type == 'cuda':\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eed2ff75",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:42.385233Z",
     "iopub.status.busy": "2025-03-19T06:30:42.385020Z",
     "iopub.status.idle": "2025-03-19T06:30:42.388303Z",
     "shell.execute_reply": "2025-03-19T06:30:42.387621Z"
    }
   },
   "outputs": [],
   "source": [
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_DIM = len(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a40f7dc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:42.390156Z",
     "iopub.status.busy": "2025-03-19T06:30:42.390003Z",
     "iopub.status.idle": "2025-03-19T06:30:42.392825Z",
     "shell.execute_reply": "2025-03-19T06:30:42.392297Z"
    }
   },
   "outputs": [],
   "source": [
    "architectures = [\n",
    "    {\"name\": \"bidirectional_gru\", \"architecture\": \"gru\", \"num_layers\": 2, \"bidirectional\": True, \"sentence_embedding_method\": \"max\"},\n",
    "    {\"name\": \"bidirectional_lstm\", \"architecture\": \"lstm\", \"num_layers\": 2, \"bidirectional\": True, \"sentence_embedding_method\": \"max\"},\n",
    "    {\"name\": \"cnn\", \"architecture\": \"cnn\", \"num_layers\": 1, \"bidirectional\": False, \"sentence_embedding_method\": \"max\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13bb0df3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:42.394247Z",
     "iopub.status.busy": "2025-03-19T06:30:42.394112Z",
     "iopub.status.idle": "2025-03-19T06:30:42.396931Z",
     "shell.execute_reply": "2025-03-19T06:30:42.396470Z"
    }
   },
   "outputs": [],
   "source": [
    "task4_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dadb10e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:42.398453Z",
     "iopub.status.busy": "2025-03-19T06:30:42.398214Z",
     "iopub.status.idle": "2025-03-19T06:30:58.231154Z",
     "shell.execute_reply": "2025-03-19T06:30:58.230534Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with architecture: bidirectional_gru\n",
      "\n",
      "The model has 2,583,606 trainable parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.556 | Train Acc: 34.86%\n",
      "\t Val. Loss: 1.162 |  Val. Acc: 63.72%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.810 | Train Acc: 70.96%\n",
      "\t Val. Loss: 0.601 |  Val. Acc: 80.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.357 | Train Acc: 89.37%\n",
      "\t Val. Loss: 0.500 |  Val. Acc: 84.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.148 | Train Acc: 96.53%\n",
      "\t Val. Loss: 0.508 |  Val. Acc: 83.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.066 | Train Acc: 98.80%\n",
      "\t Val. Loss: 0.616 |  Val. Acc: 82.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.033 | Train Acc: 99.52%\n",
      "\t Val. Loss: 0.656 |  Val. Acc: 83.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.024 | Train Acc: 99.68%\n",
      "\t Val. Loss: 0.735 |  Val. Acc: 83.07%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.016 | Train Acc: 99.82%\n",
      "\t Val. Loss: 0.855 |  Val. Acc: 79.95%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.017 | Train Acc: 99.75%\n",
      "\t Val. Loss: 0.694 |  Val. Acc: 81.42%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.012 | Train Acc: 99.84%\n",
      "\t Val. Loss: 0.770 |  Val. Acc: 80.64%\n",
      "Test Loss: 0.427 | Test Acc: 88.25%\n",
      "\n",
      "Training with architecture: bidirectional_lstm\n",
      "\n",
      "The model has 2,634,006 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2399202/1625296099.py:45: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'task4-model-{config[\"name\"]}.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.635 | Train Acc: 28.33%\n",
      "\t Val. Loss: 1.286 |  Val. Acc: 49.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.872 | Train Acc: 69.90%\n",
      "\t Val. Loss: 0.591 |  Val. Acc: 81.34%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.387 | Train Acc: 88.47%\n",
      "\t Val. Loss: 0.548 |  Val. Acc: 81.25%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.194 | Train Acc: 95.04%\n",
      "\t Val. Loss: 0.501 |  Val. Acc: 84.29%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.113 | Train Acc: 97.19%\n",
      "\t Val. Loss: 0.536 |  Val. Acc: 84.03%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.070 | Train Acc: 98.60%\n",
      "\t Val. Loss: 0.548 |  Val. Acc: 85.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.042 | Train Acc: 99.28%\n",
      "\t Val. Loss: 0.586 |  Val. Acc: 84.98%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.025 | Train Acc: 99.64%\n",
      "\t Val. Loss: 0.602 |  Val. Acc: 86.20%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.017 | Train Acc: 99.82%\n",
      "\t Val. Loss: 0.589 |  Val. Acc: 87.33%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.012 | Train Acc: 99.95%\n",
      "\t Val. Loss: 0.637 |  Val. Acc: 85.85%\n",
      "Test Loss: 0.461 | Test Acc: 84.65%\n",
      "\n",
      "Training with architecture: cnn\n",
      "\n",
      "The model has 2,567,856 trainable parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.356 | Train Acc: 49.10%\n",
      "\t Val. Loss: 0.884 |  Val. Acc: 75.26%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.713 | Train Acc: 76.58%\n",
      "\t Val. Loss: 0.537 |  Val. Acc: 83.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.401 | Train Acc: 87.88%\n",
      "\t Val. Loss: 0.399 |  Val. Acc: 86.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.234 | Train Acc: 93.75%\n",
      "\t Val. Loss: 0.334 |  Val. Acc: 87.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.133 | Train Acc: 96.78%\n",
      "\t Val. Loss: 0.317 |  Val. Acc: 85.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.078 | Train Acc: 98.37%\n",
      "\t Val. Loss: 0.323 |  Val. Acc: 87.41%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.054 | Train Acc: 98.82%\n",
      "\t Val. Loss: 0.319 |  Val. Acc: 88.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.035 | Train Acc: 99.46%\n",
      "\t Val. Loss: 0.321 |  Val. Acc: 88.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.028 | Train Acc: 99.59%\n",
      "\t Val. Loss: 0.328 |  Val. Acc: 88.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 0.019 | Train Acc: 99.80%\n",
      "\t Val. Loss: 0.343 |  Val. Acc: 87.93%\n",
      "Test Loss: 0.254 | Test Acc: 91.18%\n"
     ]
    }
   ],
   "source": [
    "for config in architectures:\n",
    "    print(f\"\\nTraining with architecture: {config['name']}\\n\")\n",
    "\n",
    "    model = SentenceClassifier(\n",
    "        vocab_size=VOCAB_SIZE,\n",
    "        embedding_dim=EMBEDDING_DIM,\n",
    "        hidden_dim=HIDDEN_DIM,\n",
    "        output_dim=OUTPUT_DIM,\n",
    "        architecture=config[\"architecture\"],\n",
    "        num_layers=config[\"num_layers\"],\n",
    "        bidirectional=config[\"bidirectional\"],\n",
    "        sentence_embedding_method=config[\"sentence_embedding_method\"],\n",
    "        dropout=0.5\n",
    "    )\n",
    "\n",
    "    model.embedding.weight.data.copy_(embedding_matrix)\n",
    "    model.embedding.weight.requires_grad = True\n",
    "\n",
    "    print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), f'task4-model-{config[\"name\"]}.pt')\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    model.load_state_dict(torch.load(f'task4-model-{config[\"name\"]}.pt'))\n",
    "    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "    print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
    "\n",
    "    task4_results[config[\"name\"]] = {\n",
    "        \"valid_loss\": best_valid_loss,\n",
    "        \"valid_acc\": valid_acc,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_acc\": test_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3c63c295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:58.233072Z",
     "iopub.status.busy": "2025-03-19T06:30:58.232710Z",
     "iopub.status.idle": "2025-03-19T06:30:58.236196Z",
     "shell.execute_reply": "2025-03-19T06:30:58.235599Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 4 Results and Comparison with Task 3 Best (max method):\n",
      "Task 3 Best (max method):\n",
      "  Validation Loss: 1.520 | Validation Acc: 44.62%\n",
      "  Test Loss: 1.527 | Test Acc: 45.00%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTask 4 Results and Comparison with Task 3 Best (max method):\")\n",
    "print(\"Task 3 Best (max method):\")\n",
    "print(f\"  Validation Loss: 1.520 | Validation Acc: 44.62%\")\n",
    "print(f\"  Test Loss: 1.527 | Test Acc: 45.00%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9c2a50a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:30:58.238389Z",
     "iopub.status.busy": "2025-03-19T06:30:58.237957Z",
     "iopub.status.idle": "2025-03-19T06:30:58.241805Z",
     "shell.execute_reply": "2025-03-19T06:30:58.241159Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 4 Results:\n",
      "Architecture: bidirectional_gru\n",
      "  Validation Loss: 0.500 | Validation Acc: 80.64%\n",
      "  Test Loss: 0.427 | Test Acc: 88.25%\n",
      "Architecture: bidirectional_lstm\n",
      "  Validation Loss: 0.501 | Validation Acc: 85.85%\n",
      "  Test Loss: 0.461 | Test Acc: 84.65%\n",
      "Architecture: cnn\n",
      "  Validation Loss: 0.317 | Validation Acc: 87.93%\n",
      "  Test Loss: 0.254 | Test Acc: 91.18%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTask 4 Results:\")\n",
    "for name, result in task4_results.items():\n",
    "    print(f\"Architecture: {name}\")\n",
    "    print(f\"  Validation Loss: {result['valid_loss']:.3f} | Validation Acc: {result['valid_acc']*100:.2f}%\")\n",
    "    print(f\"  Test Loss: {result['test_loss']:.3f} | Test Acc: {result['test_acc']*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
