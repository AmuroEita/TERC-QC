{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fb20035",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:29.756883Z",
     "iopub.status.busy": "2025-03-19T06:24:29.756736Z",
     "iopub.status.idle": "2025-03-19T06:24:31.379200Z",
     "shell.execute_reply": "2025-03-19T06:24:31.378539Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "from torchtext.vocab import GloVe, FastText, Vectors\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "import os\n",
    "import time\n",
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "afa37450",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:31.381704Z",
     "iopub.status.busy": "2025-03-19T06:24:31.381218Z",
     "iopub.status.idle": "2025-03-19T06:24:31.385654Z",
     "shell.execute_reply": "2025-03-19T06:24:31.385035Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "SEED = 1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0e47722",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:31.387660Z",
     "iopub.status.busy": "2025-03-19T06:24:31.387386Z",
     "iopub.status.idle": "2025-03-19T06:24:31.392526Z",
     "shell.execute_reply": "2025-03-19T06:24:31.392009Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, dropout_rate=0.5, pretrained_embeddings=None):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        # If pretrained embeddings are provided, load them into the embedding layer\n",
    "        if pretrained_embeddings is not None:\n",
    "            self.embedding.weight.data.copy_(pretrained_embeddings)\n",
    "            self.embedding.weight.requires_grad = True  # Allow fine-tuning of embeddings\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        batch_size = text.shape[0]\n",
    "        text_lengths = text_lengths[:batch_size]\n",
    "        max_seq_len = text.shape[1]\n",
    "        text_lengths = torch.clamp(text_lengths, min=1, max=max_seq_len)\n",
    "        text_lengths = text_lengths.cpu().long()\n",
    "        embedded = self.dropout(self.embedding(text))\n",
    "        packed_embedded = pack_padded_sequence(embedded, text_lengths, batch_first=True, enforce_sorted=False)\n",
    "        packed_output, hidden = self.rnn(packed_embedded)\n",
    "        hidden = self.dropout(hidden.squeeze(0))\n",
    "        return self.fc(hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b9ad649d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:31.394364Z",
     "iopub.status.busy": "2025-03-19T06:24:31.394119Z",
     "iopub.status.idle": "2025-03-19T06:24:31.397159Z",
     "shell.execute_reply": "2025-03-19T06:24:31.396608Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313cc7db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:31.399170Z",
     "iopub.status.busy": "2025-03-19T06:24:31.398675Z",
     "iopub.status.idle": "2025-03-19T06:24:31.403097Z",
     "shell.execute_reply": "2025-03-19T06:24:31.402615Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text, text_lengths = batch.text\n",
    "        batch_size = text.shape[0]\n",
    "        labels = batch.label[:batch_size]\n",
    "\n",
    "        predictions = model(text, text_lengths)\n",
    "        loss = criterion(predictions, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        _, predicted_classes = predictions.max(dim=1)\n",
    "        correct_predictions = (predicted_classes == labels).float()\n",
    "        batch_acc = correct_predictions.mean().item()\n",
    "        epoch_acc += batch_acc\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6717b0b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:31.404887Z",
     "iopub.status.busy": "2025-03-19T06:24:31.404690Z",
     "iopub.status.idle": "2025-03-19T06:24:31.408866Z",
     "shell.execute_reply": "2025-03-19T06:24:31.408114Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            batch_size = text.shape[0]\n",
    "            labels = batch.label[:batch_size]\n",
    "\n",
    "            predictions = model(text, text_lengths)\n",
    "            loss = criterion(predictions, labels)\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            _, predicted_classes = predictions.max(dim=1)\n",
    "            correct_predictions = (predicted_classes == labels).float()\n",
    "            batch_acc = correct_predictions.mean().item()\n",
    "            epoch_acc += batch_acc\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60723a99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:31.410976Z",
     "iopub.status.busy": "2025-03-19T06:24:31.410682Z",
     "iopub.status.idle": "2025-03-19T06:24:31.413900Z",
     "shell.execute_reply": "2025-03-19T06:24:31.413420Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Compute epoch time\n",
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "336db6be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:31.415743Z",
     "iopub.status.busy": "2025-03-19T06:24:31.415533Z",
     "iopub.status.idle": "2025-03-19T06:24:31.418010Z",
     "shell.execute_reply": "2025-03-19T06:24:31.417385Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c7dfb571",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:31.419622Z",
     "iopub.status.busy": "2025-03-19T06:24:31.419466Z",
     "iopub.status.idle": "2025-03-19T06:24:32.363770Z",
     "shell.execute_reply": "2025-03-19T06:24:32.362899Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXT = data.Field(tokenize='spacy', tokenizer_language='en_core_web_sm', include_lengths=True)\n",
    "LABEL = data.LabelField()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a447a0dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:32.366797Z",
     "iopub.status.busy": "2025-03-19T06:24:32.366072Z",
     "iopub.status.idle": "2025-03-19T06:24:32.901953Z",
     "shell.execute_reply": "2025-03-19T06:24:32.901364Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, test_data = datasets.TREC.splits(TEXT, LABEL, fine_grained=False)\n",
    "train_data, valid_data = train_data.split(split_ratio=0.8, random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90769da1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:32.904602Z",
     "iopub.status.busy": "2025-03-19T06:24:32.904329Z",
     "iopub.status.idle": "2025-03-19T06:24:32.907938Z",
     "shell.execute_reply": "2025-03-19T06:24:32.907244Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 4362\n",
      "Number of validation examples: 1090\n",
      "Number of testing examples: 500\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7d40abee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:32.910229Z",
     "iopub.status.busy": "2025-03-19T06:24:32.909574Z",
     "iopub.status.idle": "2025-03-19T06:24:32.912941Z",
     "shell.execute_reply": "2025-03-19T06:24:32.912171Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "best_params = {\n",
    "    'embedding_dim': 50,\n",
    "    'hidden_dim': 200,\n",
    "    'lr': 0.005,\n",
    "    'dropout_rate': 0.4,\n",
    "    'weight_decay': 0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37ea27d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:32.914847Z",
     "iopub.status.busy": "2025-03-19T06:24:32.914641Z",
     "iopub.status.idle": "2025-03-19T06:24:32.918923Z",
     "shell.execute_reply": "2025-03-19T06:24:32.918375Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def build_vocab_with_pretrained(embedding_type):\n",
    "    if embedding_type == 'glove':\n",
    "        TEXT.build_vocab(train_data, max_size=10000, vectors=GloVe(name='6B', dim=best_params['embedding_dim']))\n",
    "        return TEXT.vocab.vectors\n",
    "    elif embedding_type == 'fasttext':\n",
    "        TEXT.build_vocab(train_data, max_size=10000, vectors=FastText(language='en'))\n",
    "        return TEXT.vocab.vectors\n",
    "    elif embedding_type == 'word2vec':\n",
    "        # Load Word2Vec using gensim\n",
    "        word2vec_model = api.load('word2vec-google-news-300')\n",
    "        TEXT.build_vocab(train_data, max_size=10000)\n",
    "        # Create an embedding matrix for the vocabulary\n",
    "        embedding_dim = 300  # Word2Vec has 300 dimensions\n",
    "        pretrained_embeddings = torch.zeros(len(TEXT.vocab), embedding_dim)\n",
    "        for i, token in enumerate(TEXT.vocab.itos):\n",
    "            if token in word2vec_model:\n",
    "                pretrained_embeddings[i] = torch.tensor(word2vec_model[token])\n",
    "            else:\n",
    "                pretrained_embeddings[i] = torch.randn(embedding_dim)  # Random init for OOV\n",
    "        return pretrained_embeddings\n",
    "    else:\n",
    "        TEXT.build_vocab(train_data, max_size=10000)  # No pretrained embeddings (Task 1)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3394b1e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:32.920801Z",
     "iopub.status.busy": "2025-03-19T06:24:32.920517Z",
     "iopub.status.idle": "2025-03-19T06:24:32.924420Z",
     "shell.execute_reply": "2025-03-19T06:24:32.923657Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ffec24f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:32.926497Z",
     "iopub.status.busy": "2025-03-19T06:24:32.926030Z",
     "iopub.status.idle": "2025-03-19T06:24:32.931485Z",
     "shell.execute_reply": "2025-03-19T06:24:32.930961Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_task1():\n",
    "    print(\"\\n=== Running Task 1 with Best Hyperparameters ===\")\n",
    "    pretrained_embeddings = build_vocab_with_pretrained(None)  # No pretrained embeddings\n",
    "\n",
    "    LABEL.build_vocab(train_data)\n",
    "    VOCAB_SIZE = len(TEXT.vocab)\n",
    "    OUTPUT_DIM = len(LABEL.vocab)\n",
    "    model = RNN(\n",
    "        VOCAB_SIZE,\n",
    "        best_params['embedding_dim'],\n",
    "        best_params['hidden_dim'],\n",
    "        OUTPUT_DIM,\n",
    "        best_params['dropout_rate'],\n",
    "        pretrained_embeddings=pretrained_embeddings\n",
    "    ).to(device)\n",
    "\n",
    "    print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    best_valid_acc = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_valid_acc = valid_acc\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\tVal. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    model.load_state_dict(best_model_state)\n",
    "    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "    print(f\"\\nTask 1 Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%\")\n",
    "\n",
    "    return best_valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dcf0ae65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:32.933419Z",
     "iopub.status.busy": "2025-03-19T06:24:32.932948Z",
     "iopub.status.idle": "2025-03-19T06:24:32.938332Z",
     "shell.execute_reply": "2025-03-19T06:24:32.937790Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def run_task2(embedding_type):\n",
    "    print(f\"\\n=== Running Task 2 with {embedding_type.capitalize()} Embeddings ===\")\n",
    "    \n",
    "    # Build vocabulary and load pretrained embeddings\n",
    "    pretrained_embeddings = build_vocab_with_pretrained(embedding_type)\n",
    "\n",
    "    LABEL.build_vocab(train_data)\n",
    "    VOCAB_SIZE = len(TEXT.vocab)\n",
    "    OUTPUT_DIM = len(LABEL.vocab)\n",
    "    embedding_dim = best_params['embedding_dim']\n",
    "    if pretrained_embeddings is not None:\n",
    "        embedding_dim = pretrained_embeddings.shape[1]\n",
    "\n",
    "    model = RNN(\n",
    "        VOCAB_SIZE,\n",
    "        embedding_dim,\n",
    "        best_params['hidden_dim'],\n",
    "        OUTPUT_DIM,\n",
    "        best_params['dropout_rate'],\n",
    "        pretrained_embeddings=pretrained_embeddings\n",
    "    ).to(device)\n",
    "\n",
    "    print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=best_params['lr'], weight_decay=best_params['weight_decay'])\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "    best_valid_acc = 0\n",
    "    best_model_state = None\n",
    "\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            best_valid_acc = valid_acc\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\tVal. Loss: {valid_loss:.3f} | Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    # Load the best model and evaluate on the test set\n",
    "    model.load_state_dict(best_model_state)\n",
    "    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "    print(f\"\\nTask 2 ({embedding_type.capitalize()}) Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%\")\n",
    "\n",
    "    return best_valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d56810f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:32.940223Z",
     "iopub.status.busy": "2025-03-19T06:24:32.939792Z",
     "iopub.status.idle": "2025-03-19T06:24:39.080265Z",
     "shell.execute_reply": "2025-03-19T06:24:39.079489Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Task 1 with Best Hyperparameters ===\n",
      "The model has 456,906 trainable parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 0s\n",
      "\tTrain Loss: 1.824 | Train Acc: 16.05%\n",
      "\tVal. Loss: 1.788 | Val. Acc: 17.92%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 0s\n",
      "\tTrain Loss: 1.797 | Train Acc: 16.71%\n",
      "\tVal. Loss: 1.767 | Val. Acc: 18.68%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 0s\n",
      "\tTrain Loss: 1.761 | Train Acc: 22.64%\n",
      "\tVal. Loss: 1.751 | Val. Acc: 22.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 0s\n",
      "\tTrain Loss: 1.772 | Train Acc: 19.78%\n",
      "\tVal. Loss: 1.735 | Val. Acc: 22.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 0s\n",
      "\tTrain Loss: 1.739 | Train Acc: 22.77%\n",
      "\tVal. Loss: 1.721 | Val. Acc: 22.40%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 0s\n",
      "\tTrain Loss: 1.715 | Train Acc: 24.71%\n",
      "\tVal. Loss: 1.710 | Val. Acc: 23.53%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 0s\n",
      "\tTrain Loss: 1.733 | Train Acc: 21.29%\n",
      "\tVal. Loss: 1.699 | Val. Acc: 24.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 0s\n",
      "\tTrain Loss: 1.715 | Train Acc: 21.91%\n",
      "\tVal. Loss: 1.692 | Val. Acc: 23.62%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 0s\n",
      "\tTrain Loss: 1.701 | Train Acc: 22.80%\n",
      "\tVal. Loss: 1.684 | Val. Acc: 24.04%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 0s\n",
      "\tTrain Loss: 1.717 | Train Acc: 21.75%\n",
      "\tVal. Loss: 1.676 | Val. Acc: 24.33%\n",
      "\n",
      "Task 1 Test Loss: 1.680 | Test Acc: 27.56%\n"
     ]
    }
   ],
   "source": [
    "task1_valid_acc, task1_test_acc = run_task1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77715302",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:39.082636Z",
     "iopub.status.busy": "2025-03-19T06:24:39.082096Z",
     "iopub.status.idle": "2025-03-19T06:24:39.085298Z",
     "shell.execute_reply": "2025-03-19T06:24:39.084789Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_types = ['glove', 'fasttext', 'word2vec']\n",
    "task2_results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8235485f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:24:39.086926Z",
     "iopub.status.busy": "2025-03-19T06:24:39.086780Z",
     "iopub.status.idle": "2025-03-19T06:25:37.456913Z",
     "shell.execute_reply": "2025-03-19T06:25:37.455961Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Running Task 2 with Glove Embeddings ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junyao/.local/lib/python3.10/site-packages/torchtext/vocab.py:432: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.itos, self.stoi, self.vectors, self.dim = torch.load(path_pt)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 456,906 trainable parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 0s\n",
      "\tTrain Loss: 1.778 | Train Acc: 19.71%\n",
      "\tVal. Loss: 1.727 | Val. Acc: 25.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 0s\n",
      "\tTrain Loss: 1.728 | Train Acc: 21.47%\n",
      "\tVal. Loss: 1.691 | Val. Acc: 26.45%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 0s\n",
      "\tTrain Loss: 1.700 | Train Acc: 23.06%\n",
      "\tVal. Loss: 1.670 | Val. Acc: 25.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 0s\n",
      "\tTrain Loss: 1.694 | Train Acc: 20.36%\n",
      "\tVal. Loss: 1.657 | Val. Acc: 24.01%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 0s\n",
      "\tTrain Loss: 1.695 | Train Acc: 21.71%\n",
      "\tVal. Loss: 1.651 | Val. Acc: 24.75%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 0s\n",
      "\tTrain Loss: 1.685 | Train Acc: 22.48%\n",
      "\tVal. Loss: 1.650 | Val. Acc: 24.80%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 0s\n",
      "\tTrain Loss: 1.684 | Train Acc: 21.42%\n",
      "\tVal. Loss: 1.643 | Val. Acc: 25.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 0s\n",
      "\tTrain Loss: 1.691 | Train Acc: 21.12%\n",
      "\tVal. Loss: 1.640 | Val. Acc: 26.41%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 0s\n",
      "\tTrain Loss: 1.665 | Train Acc: 21.17%\n",
      "\tVal. Loss: 1.635 | Val. Acc: 27.14%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 1s\n",
      "\tTrain Loss: 1.667 | Train Acc: 23.84%\n",
      "\tVal. Loss: 1.630 | Val. Acc: 24.21%\n",
      "\n",
      "Task 2 (Glove) Test Loss: 1.645 | Test Acc: 17.54%\n",
      "\n",
      "=== Running Task 2 with Fasttext Embeddings ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,533,406 trainable parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 0s\n",
      "\tTrain Loss: 1.763 | Train Acc: 22.16%\n",
      "\tVal. Loss: 1.733 | Val. Acc: 22.02%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 0s\n",
      "\tTrain Loss: 1.726 | Train Acc: 22.25%\n",
      "\tVal. Loss: 1.703 | Val. Acc: 22.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 0s\n",
      "\tTrain Loss: 1.703 | Train Acc: 23.14%\n",
      "\tVal. Loss: 1.680 | Val. Acc: 23.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 0s\n",
      "\tTrain Loss: 1.680 | Train Acc: 22.96%\n",
      "\tVal. Loss: 1.664 | Val. Acc: 22.09%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 0s\n",
      "\tTrain Loss: 1.681 | Train Acc: 20.78%\n",
      "\tVal. Loss: 1.654 | Val. Acc: 22.13%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 0s\n",
      "\tTrain Loss: 1.674 | Train Acc: 21.94%\n",
      "\tVal. Loss: 1.647 | Val. Acc: 23.03%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 0s\n",
      "\tTrain Loss: 1.656 | Train Acc: 22.74%\n",
      "\tVal. Loss: 1.639 | Val. Acc: 23.76%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 0s\n",
      "\tTrain Loss: 1.660 | Train Acc: 20.55%\n",
      "\tVal. Loss: 1.636 | Val. Acc: 22.41%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 0s\n",
      "\tTrain Loss: 1.689 | Train Acc: 20.70%\n",
      "\tVal. Loss: 1.635 | Val. Acc: 24.24%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 0s\n",
      "\tTrain Loss: 1.660 | Train Acc: 21.57%\n",
      "\tVal. Loss: 1.635 | Val. Acc: 22.73%\n",
      "\n",
      "Task 2 (Fasttext) Test Loss: 1.667 | Test Acc: 20.09%\n",
      "\n",
      "=== Running Task 2 with Word2vec Embeddings ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 2,533,406 trainable parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 0m 0s\n",
      "\tTrain Loss: 1.793 | Train Acc: 19.11%\n",
      "\tVal. Loss: 1.747 | Val. Acc: 20.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Time: 0m 0s\n",
      "\tTrain Loss: 1.765 | Train Acc: 23.76%\n",
      "\tVal. Loss: 1.727 | Val. Acc: 21.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Time: 0m 0s\n",
      "\tTrain Loss: 1.739 | Train Acc: 22.56%\n",
      "\tVal. Loss: 1.710 | Val. Acc: 21.86%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Time: 0m 0s\n",
      "\tTrain Loss: 1.733 | Train Acc: 22.91%\n",
      "\tVal. Loss: 1.700 | Val. Acc: 20.05%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Time: 0m 0s\n",
      "\tTrain Loss: 1.720 | Train Acc: 22.69%\n",
      "\tVal. Loss: 1.693 | Val. Acc: 20.48%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Time: 0m 0s\n",
      "\tTrain Loss: 1.700 | Train Acc: 23.29%\n",
      "\tVal. Loss: 1.679 | Val. Acc: 21.03%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Time: 0m 0s\n",
      "\tTrain Loss: 1.704 | Train Acc: 23.02%\n",
      "\tVal. Loss: 1.671 | Val. Acc: 24.49%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Time: 0m 0s\n",
      "\tTrain Loss: 1.686 | Train Acc: 25.55%\n",
      "\tVal. Loss: 1.665 | Val. Acc: 24.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Time: 0m 0s\n",
      "\tTrain Loss: 1.710 | Train Acc: 21.65%\n",
      "\tVal. Loss: 1.660 | Val. Acc: 25.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Time: 0m 0s\n",
      "\tTrain Loss: 1.691 | Train Acc: 22.80%\n",
      "\tVal. Loss: 1.655 | Val. Acc: 23.71%\n",
      "\n",
      "Task 2 (Word2vec) Test Loss: 1.675 | Test Acc: 27.83%\n"
     ]
    }
   ],
   "source": [
    "for emb_type in embedding_types:\n",
    "    valid_acc, test_acc = run_task2(emb_type)\n",
    "    task2_results[emb_type] = {'valid_acc': valid_acc, 'test_acc': test_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "218484be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:37.459425Z",
     "iopub.status.busy": "2025-03-19T06:25:37.459122Z",
     "iopub.status.idle": "2025-03-19T06:25:37.462907Z",
     "shell.execute_reply": "2025-03-19T06:25:37.462022Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Final Results ===\n",
      "\n",
      "Task 1 Results (Best Hyperparameters):\n",
      "Validation Accuracy: 24.33%\n",
      "Test Accuracy: 27.56%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Final Results ===\")\n",
    "print(f\"\\nTask 1 Results (Best Hyperparameters):\")\n",
    "print(f\"Validation Accuracy: {task1_valid_acc*100:.2f}%\")\n",
    "print(f\"Test Accuracy: {task1_test_acc*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba85944f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:37.465019Z",
     "iopub.status.busy": "2025-03-19T06:25:37.464829Z",
     "iopub.status.idle": "2025-03-19T06:25:37.468086Z",
     "shell.execute_reply": "2025-03-19T06:25:37.467566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Task 2 Results with Pre-trained Embeddings:\n",
      "\n",
      "Glove Embeddings:\n",
      "Validation Accuracy: 24.21%\n",
      "Test Accuracy: 17.54%\n",
      "\n",
      "Fasttext Embeddings:\n",
      "Validation Accuracy: 24.24%\n",
      "Test Accuracy: 20.09%\n",
      "\n",
      "Word2vec Embeddings:\n",
      "Validation Accuracy: 23.71%\n",
      "Test Accuracy: 27.83%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTask 2 Results with Pre-trained Embeddings:\")\n",
    "for emb_type, result in task2_results.items():\n",
    "    print(f\"\\n{emb_type.capitalize()} Embeddings:\")\n",
    "    print(f\"Validation Accuracy: {result['valid_acc']*100:.2f}%\")\n",
    "    print(f\"Test Accuracy: {result['test_acc']*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fc8a8cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:37.470136Z",
     "iopub.status.busy": "2025-03-19T06:25:37.469734Z",
     "iopub.status.idle": "2025-03-19T06:25:37.473103Z",
     "shell.execute_reply": "2025-03-19T06:25:37.472401Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Comparison and Analysis ===\n",
      "\n",
      "Glove vs Task 1:\n",
      "Validation Accuracy Difference: -0.12%\n",
      "Test Accuracy Difference: -10.02%\n",
      "\n",
      "Fasttext vs Task 1:\n",
      "Validation Accuracy Difference: -0.08%\n",
      "Test Accuracy Difference: -7.47%\n",
      "\n",
      "Word2vec vs Task 1:\n",
      "Validation Accuracy Difference: -0.62%\n",
      "Test Accuracy Difference: +0.27%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== Comparison and Analysis ===\")\n",
    "for emb_type, result in task2_results.items():\n",
    "    valid_diff = result['valid_acc'] - task1_valid_acc\n",
    "    test_diff = result['test_acc'] - task1_test_acc\n",
    "    print(f\"\\n{emb_type.capitalize()} vs Task 1:\")\n",
    "    print(f\"Validation Accuracy Difference: {valid_diff*100:+.2f}%\")\n",
    "    print(f\"Test Accuracy Difference: {test_diff*100:+.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
