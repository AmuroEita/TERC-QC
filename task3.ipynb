{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4f1b8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:51.216932Z",
     "iopub.status.busy": "2025-03-19T06:25:51.216495Z",
     "iopub.status.idle": "2025-03-19T06:25:54.219489Z",
     "shell.execute_reply": "2025-03-19T06:25:54.218729Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "from torchtext import data\n",
    "from torchtext import datasets\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import os\n",
    "import gensim.downloader as api\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b65adf12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:54.222099Z",
     "iopub.status.busy": "2025-03-19T06:25:54.221745Z",
     "iopub.status.idle": "2025-03-19T06:25:54.224713Z",
     "shell.execute_reply": "2025-03-19T06:25:54.224210Z"
    }
   },
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e1f48a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:54.226615Z",
     "iopub.status.busy": "2025-03-19T06:25:54.226245Z",
     "iopub.status.idle": "2025-03-19T06:25:54.228646Z",
     "shell.execute_reply": "2025-03-19T06:25:54.228235Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "BATCH_SIZE = 64\n",
    "N_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b56ae408",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:54.230172Z",
     "iopub.status.busy": "2025-03-19T06:25:54.230021Z",
     "iopub.status.idle": "2025-03-19T06:25:54.233653Z",
     "shell.execute_reply": "2025-03-19T06:25:54.233236Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "967ec14b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:54.235501Z",
     "iopub.status.busy": "2025-03-19T06:25:54.235071Z",
     "iopub.status.idle": "2025-03-19T06:25:54.242892Z",
     "shell.execute_reply": "2025-03-19T06:25:54.242172Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, sentence_embedding_method=\"last\", use_packing=True, dropout=0.0):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "        self.sentence_embedding_method = sentence_embedding_method\n",
    "        self.use_packing = use_packing\n",
    "        self.dropout = nn.Dropout(dropout)  \n",
    "\n",
    "        if self.sentence_embedding_method == \"attention\":\n",
    "            self.attention = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        vocab_size = self.embedding.num_embeddings\n",
    "        if text.max().item() >= vocab_size:\n",
    "            raise ValueError(f\"Text contains indices out of vocab range: max index {text.max().item()} >= vocab size {vocab_size}\")\n",
    "\n",
    "        if (text_lengths <= 0).any():\n",
    "            raise ValueError(f\"text_lengths contains non-positive values: {text_lengths}\")\n",
    "        if (text_lengths > text.shape[1]).any():\n",
    "            raise ValueError(f\"text_lengths contains values larger than sequence length: {text_lengths}, max seq length: {text.shape[1]}\")\n",
    "\n",
    "        embedded = self.embedding(text)\n",
    "\n",
    "        if self.use_packing:\n",
    "            try:\n",
    "                text_lengths_cpu = text_lengths.cpu().to(torch.int64)\n",
    "                if torch.cuda.is_available() and text.device.type == 'cuda':\n",
    "                    torch.cuda.synchronize()\n",
    "                packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths_cpu, batch_first=True, enforce_sorted=False)\n",
    "                packed_output, hidden = self.rnn(packed_embedded)\n",
    "                output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)\n",
    "            except Exception as e:\n",
    "                print(\"Error in pack_padded_sequence:\", e)\n",
    "                raise\n",
    "        else:\n",
    "            output, hidden = self.rnn(embedded)\n",
    "\n",
    "        if self.sentence_embedding_method == \"last\":\n",
    "            sentence_embedding = hidden.squeeze(0)\n",
    "        elif self.sentence_embedding_method == \"mean\":\n",
    "            sentence_embedding = torch.mean(output, dim=1)\n",
    "        elif self.sentence_embedding_method == \"max\":\n",
    "            sentence_embedding = torch.max(output, dim=1)[0]\n",
    "        elif self.sentence_embedding_method == \"attention\":\n",
    "            attn_weights = self.attention(output)\n",
    "            attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "            sentence_embedding = torch.sum(output * attn_weights, dim=1)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown sentence embedding method!\")\n",
    "\n",
    "        sentence_embedding = self.dropout(sentence_embedding)\n",
    "        return self.fc(sentence_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b96c14e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:54.245057Z",
     "iopub.status.busy": "2025-03-19T06:25:54.244633Z",
     "iopub.status.idle": "2025-03-19T06:25:54.247697Z",
     "shell.execute_reply": "2025-03-19T06:25:54.247129Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Define utility functions\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e2d0274",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:54.249775Z",
     "iopub.status.busy": "2025-03-19T06:25:54.249452Z",
     "iopub.status.idle": "2025-03-19T06:25:54.252477Z",
     "shell.execute_reply": "2025-03-19T06:25:54.251854Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47e25456",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:54.254478Z",
     "iopub.status.busy": "2025-03-19T06:25:54.253979Z",
     "iopub.status.idle": "2025-03-19T06:25:54.258109Z",
     "shell.execute_reply": "2025-03-19T06:25:54.257631Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.train()\n",
    "\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "        text, text_lengths = batch.text\n",
    "\n",
    "        predictions = model(text, text_lengths).squeeze(1)\n",
    "        loss = criterion(predictions, batch.label)\n",
    "\n",
    "        _, predicted = torch.max(predictions, 1)\n",
    "        correct = (predicted == batch.label).float()\n",
    "        acc = correct.sum() / len(batch.label)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "158c40a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:54.259852Z",
     "iopub.status.busy": "2025-03-19T06:25:54.259417Z",
     "iopub.status.idle": "2025-03-19T06:25:54.263566Z",
     "shell.execute_reply": "2025-03-19T06:25:54.262916Z"
    },
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            text, text_lengths = batch.text\n",
    "            predictions = model(text, text_lengths).squeeze(1)\n",
    "            loss = criterion(predictions, batch.label)\n",
    "\n",
    "            _, predicted = torch.max(predictions, 1)\n",
    "            correct = (predicted == batch.label).float()\n",
    "            acc = correct.sum() / len(batch.label)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23bd2a8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:54.265462Z",
     "iopub.status.busy": "2025-03-19T06:25:54.265039Z",
     "iopub.status.idle": "2025-03-19T06:25:55.197034Z",
     "shell.execute_reply": "2025-03-19T06:25:55.196260Z"
    }
   },
   "outputs": [],
   "source": [
    "# For tokenization\n",
    "TEXT = data.Field(tokenize='spacy',\n",
    "                  tokenizer_language='en_core_web_sm',\n",
    "                  include_lengths=True,\n",
    "                  pad_first=False,  # Ensure padding doesn't interfere with length calculation\n",
    "                  batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66f0c8fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:55.199693Z",
     "iopub.status.busy": "2025-03-19T06:25:55.199280Z",
     "iopub.status.idle": "2025-03-19T06:25:55.202663Z",
     "shell.execute_reply": "2025-03-19T06:25:55.201874Z"
    }
   },
   "outputs": [],
   "source": [
    "# For multi-class classification labels\n",
    "LABEL = data.LabelField(dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e2798ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:55.204298Z",
     "iopub.status.busy": "2025-03-19T06:25:55.204121Z",
     "iopub.status.idle": "2025-03-19T06:25:55.713178Z",
     "shell.execute_reply": "2025-03-19T06:25:55.712624Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load the TREC dataset\n",
    "train_data, test_data = datasets.TREC.splits(TEXT, LABEL, fine_grained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e1438ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:55.716083Z",
     "iopub.status.busy": "2025-03-19T06:25:55.715603Z",
     "iopub.status.idle": "2025-03-19T06:25:55.719733Z",
     "shell.execute_reply": "2025-03-19T06:25:55.719180Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 5452\n",
      "Number of testing examples: 500\n",
      "{'text': ['How', 'did', 'serfdom', 'develop', 'in', 'and', 'then', 'leave', 'Russia', '?'], 'label': 'DESC'}\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')\n",
    "print(vars(train_data.examples[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf37eeed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:55.721104Z",
     "iopub.status.busy": "2025-03-19T06:25:55.720960Z",
     "iopub.status.idle": "2025-03-19T06:25:55.726029Z",
     "shell.execute_reply": "2025-03-19T06:25:55.725572Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, valid_data = train_data.split(split_ratio=0.8, random_state=random.seed(SEED))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "91b14812",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:55.727990Z",
     "iopub.status.busy": "2025-03-19T06:25:55.727691Z",
     "iopub.status.idle": "2025-03-19T06:25:55.730850Z",
     "shell.execute_reply": "2025-03-19T06:25:55.730302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 4362\n",
      "Number of validation examples: 1090\n",
      "Number of testing examples: 500\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')\n",
    "print(f'Number of testing examples: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf9eafe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:55.732858Z",
     "iopub.status.busy": "2025-03-19T06:25:55.732362Z",
     "iopub.status.idle": "2025-03-19T06:25:55.755043Z",
     "shell.execute_reply": "2025-03-19T06:25:55.754495Z"
    }
   },
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, max_size=10000)\n",
    "LABEL.build_vocab(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8aa45a35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:55.757477Z",
     "iopub.status.busy": "2025-03-19T06:25:55.757027Z",
     "iopub.status.idle": "2025-03-19T06:25:55.760590Z",
     "shell.execute_reply": "2025-03-19T06:25:55.759974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary: 8106\n",
      "Unique tokens in LABEL vocabulary: 6\n"
     ]
    }
   ],
   "source": [
    "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\n",
    "print(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ba268e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:25:55.762347Z",
     "iopub.status.busy": "2025-03-19T06:25:55.761973Z",
     "iopub.status.idle": "2025-03-19T06:26:33.772220Z",
     "shell.execute_reply": "2025-03-19T06:26:33.771624Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load pre-trained Word2Vec embeddings\n",
    "word2vec_vectors = api.load('word2vec-google-news-300')\n",
    "embedding_dim = 300\n",
    "vocab_size = len(TEXT.vocab)\n",
    "embedding_matrix = np.random.uniform(-0.25, 0.25, (vocab_size, embedding_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3ec76f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:26:33.774684Z",
     "iopub.status.busy": "2025-03-19T06:26:33.774255Z",
     "iopub.status.idle": "2025-03-19T06:26:33.797291Z",
     "shell.execute_reply": "2025-03-19T06:26:33.796652Z"
    }
   },
   "outputs": [],
   "source": [
    "for word, idx in TEXT.vocab.stoi.items():\n",
    "    if word in word2vec_vectors:\n",
    "        embedding_matrix[idx] = word2vec_vectors[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3af679ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:26:33.799795Z",
     "iopub.status.busy": "2025-03-19T06:26:33.799461Z",
     "iopub.status.idle": "2025-03-19T06:26:33.805446Z",
     "shell.execute_reply": "2025-03-19T06:26:33.804732Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix = torch.FloatTensor(embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "437a62a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:26:33.807263Z",
     "iopub.status.busy": "2025-03-19T06:26:33.807073Z",
     "iopub.status.idle": "2025-03-19T06:26:33.810534Z",
     "shell.execute_reply": "2025-03-19T06:26:33.810074Z"
    }
   },
   "outputs": [],
   "source": [
    "# Temporarily use CPU to debug\n",
    "device = torch.device('cuda')  # Change back to 'cuda' if resolved\n",
    "train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    sort_within_batch=True,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e7e368e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:26:33.812200Z",
     "iopub.status.busy": "2025-03-19T06:26:33.812031Z",
     "iopub.status.idle": "2025-03-19T06:26:33.814648Z",
     "shell.execute_reply": "2025-03-19T06:26:33.814171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "EMBEDDING_DIM = 300\n",
    "HIDDEN_DIM = 50\n",
    "OUTPUT_DIM = len(LABEL.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5689ed5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:26:33.816186Z",
     "iopub.status.busy": "2025-03-19T06:26:33.815870Z",
     "iopub.status.idle": "2025-03-19T06:26:33.818656Z",
     "shell.execute_reply": "2025-03-19T06:26:33.818213Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define different sentence embedding methods to test\n",
    "sentence_embedding_methods = [\"last\", \"mean\", \"max\", \"attention\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ac7d8e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:26:33.820130Z",
     "iopub.status.busy": "2025-03-19T06:26:33.819982Z",
     "iopub.status.idle": "2025-03-19T06:26:33.822314Z",
     "shell.execute_reply": "2025-03-19T06:26:33.821903Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dictionary to store results\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "405b2aea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:26:33.824538Z",
     "iopub.status.busy": "2025-03-19T06:26:33.824143Z",
     "iopub.status.idle": "2025-03-19T06:26:46.147151Z",
     "shell.execute_reply": "2025-03-19T06:26:46.146379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with sentence embedding method: last\n",
      "\n",
      "The model has 2,449,706 trainable parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.745 | Train Acc: 21.02%\n",
      "\t Val. Loss: 1.716 |  Val. Acc: 21.79%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.693 | Train Acc: 23.10%\n",
      "\t Val. Loss: 1.683 |  Val. Acc: 21.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.672 | Train Acc: 23.87%\n",
      "\t Val. Loss: 1.668 |  Val. Acc: 22.66%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.661 | Train Acc: 24.13%\n",
      "\t Val. Loss: 1.658 |  Val. Acc: 23.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.654 | Train Acc: 24.57%\n",
      "\t Val. Loss: 1.651 |  Val. Acc: 22.66%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.649 | Train Acc: 25.66%\n",
      "\t Val. Loss: 1.648 |  Val. Acc: 23.78%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.645 | Train Acc: 25.81%\n",
      "\t Val. Loss: 1.643 |  Val. Acc: 24.31%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.642 | Train Acc: 26.70%\n",
      "\t Val. Loss: 1.639 |  Val. Acc: 24.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.639 | Train Acc: 27.03%\n",
      "\t Val. Loss: 1.637 |  Val. Acc: 24.22%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.636 | Train Acc: 28.03%\n",
      "\t Val. Loss: 1.633 |  Val. Acc: 25.26%\n",
      "Test Loss: 1.657 | Test Acc: 32.03%\n",
      "\n",
      "Training with sentence embedding method: mean\n",
      "\n",
      "The model has 2,449,706 trainable parameters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2398684/3932775759.py:42: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(f'task3-model-{method}.pt'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.755 | Train Acc: 21.03%\n",
      "\t Val. Loss: 1.729 |  Val. Acc: 25.17%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.718 | Train Acc: 22.02%\n",
      "\t Val. Loss: 1.701 |  Val. Acc: 22.48%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.694 | Train Acc: 23.62%\n",
      "\t Val. Loss: 1.681 |  Val. Acc: 25.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.676 | Train Acc: 24.99%\n",
      "\t Val. Loss: 1.664 |  Val. Acc: 28.30%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.661 | Train Acc: 27.28%\n",
      "\t Val. Loss: 1.650 |  Val. Acc: 29.51%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.650 | Train Acc: 28.26%\n",
      "\t Val. Loss: 1.639 |  Val. Acc: 32.03%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.640 | Train Acc: 30.88%\n",
      "\t Val. Loss: 1.630 |  Val. Acc: 36.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.631 | Train Acc: 32.16%\n",
      "\t Val. Loss: 1.620 |  Val. Acc: 40.19%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.622 | Train Acc: 35.58%\n",
      "\t Val. Loss: 1.611 |  Val. Acc: 41.93%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.613 | Train Acc: 37.67%\n",
      "\t Val. Loss: 1.601 |  Val. Acc: 41.84%\n",
      "Test Loss: 1.617 | Test Acc: 45.84%\n",
      "\n",
      "Training with sentence embedding method: max\n",
      "\n",
      "The model has 2,449,706 trainable parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.738 | Train Acc: 22.72%\n",
      "\t Val. Loss: 1.683 |  Val. Acc: 22.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.678 | Train Acc: 24.53%\n",
      "\t Val. Loss: 1.650 |  Val. Acc: 23.35%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.654 | Train Acc: 28.13%\n",
      "\t Val. Loss: 1.631 |  Val. Acc: 27.08%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.637 | Train Acc: 31.16%\n",
      "\t Val. Loss: 1.618 |  Val. Acc: 30.90%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.624 | Train Acc: 34.77%\n",
      "\t Val. Loss: 1.604 |  Val. Acc: 39.32%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.611 | Train Acc: 36.73%\n",
      "\t Val. Loss: 1.590 |  Val. Acc: 40.71%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.598 | Train Acc: 38.03%\n",
      "\t Val. Loss: 1.577 |  Val. Acc: 42.01%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.583 | Train Acc: 40.05%\n",
      "\t Val. Loss: 1.561 |  Val. Acc: 43.14%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.567 | Train Acc: 41.95%\n",
      "\t Val. Loss: 1.540 |  Val. Acc: 43.23%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.546 | Train Acc: 41.10%\n",
      "\t Val. Loss: 1.520 |  Val. Acc: 44.62%\n",
      "Test Loss: 1.527 | Test Acc: 45.00%\n",
      "\n",
      "Training with sentence embedding method: attention\n",
      "\n",
      "The model has 2,449,757 trainable parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.784 | Train Acc: 17.69%\n",
      "\t Val. Loss: 1.747 |  Val. Acc: 23.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 02 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.726 | Train Acc: 23.35%\n",
      "\t Val. Loss: 1.704 |  Val. Acc: 24.57%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 03 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.692 | Train Acc: 25.09%\n",
      "\t Val. Loss: 1.676 |  Val. Acc: 23.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 04 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.669 | Train Acc: 26.51%\n",
      "\t Val. Loss: 1.655 |  Val. Acc: 27.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 05 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.652 | Train Acc: 28.16%\n",
      "\t Val. Loss: 1.640 |  Val. Acc: 28.39%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 06 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.640 | Train Acc: 29.63%\n",
      "\t Val. Loss: 1.627 |  Val. Acc: 32.64%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 07 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.629 | Train Acc: 31.76%\n",
      "\t Val. Loss: 1.616 |  Val. Acc: 35.85%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 08 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.618 | Train Acc: 33.93%\n",
      "\t Val. Loss: 1.605 |  Val. Acc: 39.32%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 09 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.607 | Train Acc: 35.83%\n",
      "\t Val. Loss: 1.594 |  Val. Acc: 41.15%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 | Epoch Time: 0m 0s\n",
      "\tTrain Loss: 1.595 | Train Acc: 36.77%\n",
      "\t Val. Loss: 1.580 |  Val. Acc: 42.62%\n",
      "Test Loss: 1.610 | Test Acc: 45.13%\n"
     ]
    }
   ],
   "source": [
    "# Loop over different sentence embedding methods\n",
    "for method in sentence_embedding_methods:\n",
    "    print(f\"\\nTraining with sentence embedding method: {method}\\n\")\n",
    "\n",
    "    # Initialize the model (disable packing for debugging)\n",
    "    model = RNN(VOCAB_SIZE, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM, sentence_embedding_method=method, use_packing=True)\n",
    "\n",
    "    # Load pre-trained embeddings\n",
    "    model.embedding.weight.data.copy_(embedding_matrix)\n",
    "    model.embedding.weight.requires_grad = True\n",
    "\n",
    "    print(f'The model has {count_parameters(model):,} trainable parameters')\n",
    "\n",
    "    # Move model to device\n",
    "    model = model.to(device)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    criterion = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    best_valid_loss = float('inf')\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss, train_acc = train(model, train_iterator, optimizer, criterion)\n",
    "        valid_loss, valid_acc = evaluate(model, valid_iterator, criterion)\n",
    "\n",
    "        end_time = time.time()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), f'task3-model-{method}.pt')\n",
    "\n",
    "        print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "\n",
    "    # Load the best model and evaluate on the test set\n",
    "    model.load_state_dict(torch.load(f'task3-model-{method}.pt'))\n",
    "    test_loss, test_acc = evaluate(model, test_iterator, criterion)\n",
    "    print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
    "\n",
    "    # Store results\n",
    "    results[method] = {\n",
    "        \"valid_loss\": best_valid_loss,\n",
    "        \"valid_acc\": valid_acc,\n",
    "        \"test_loss\": test_loss,\n",
    "        \"test_acc\": test_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22d05449",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T06:26:46.149913Z",
     "iopub.status.busy": "2025-03-19T06:26:46.149399Z",
     "iopub.status.idle": "2025-03-19T06:26:46.153128Z",
     "shell.execute_reply": "2025-03-19T06:26:46.152574Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison with Task 2:\n",
      "Method: last\n",
      "  Validation Loss: 1.633 | Validation Acc: 25.26%\n",
      "  Test Loss: 1.657 | Test Acc: 32.03%\n",
      "Method: mean\n",
      "  Validation Loss: 1.601 | Validation Acc: 41.84%\n",
      "  Test Loss: 1.617 | Test Acc: 45.84%\n",
      "Method: max\n",
      "  Validation Loss: 1.520 | Validation Acc: 44.62%\n",
      "  Test Loss: 1.527 | Test Acc: 45.00%\n",
      "Method: attention\n",
      "  Validation Loss: 1.580 | Validation Acc: 42.62%\n",
      "  Test Loss: 1.610 | Test Acc: 45.13%\n"
     ]
    }
   ],
   "source": [
    "# Print comparison of all methods\n",
    "print(\"\\nComparison with Task 2:\")\n",
    "for method, result in results.items():\n",
    "    print(f\"Method: {method}\")\n",
    "    print(f\"  Validation Loss: {result['valid_loss']:.3f} | Validation Acc: {result['valid_acc']*100:.2f}%\")\n",
    "    print(f\"  Test Loss: {result['test_loss']:.3f} | Test Acc: {result['test_acc']*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
